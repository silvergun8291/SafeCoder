import sys
import os
import uuid
from pathlib import Path
from tqdm import tqdm
from typing import List

from qdrant_client import QdrantClient, models
from qdrant_client.models import Distance, VectorParams, PointStruct
from langchain.schema.document import Document
from langchain_community.document_loaders import DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# Text RAG ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
from langchain_upstage.embeddings import UpstageEmbeddings

# ë¡œì»¬ ì„¤ì • íŒŒì¼ ì„í¬íŠ¸
try:
    from config_db import (
        QDRANT_URL, QDRANT_API_KEY, UPSTAGE_API_KEY,
        TEXT_COLLECTION_NAME, RULE_COLLECTION_NAME, TEXT_EMBEDDING_MODEL,
        TEXT_VECTOR_DIMENSION, TEXT_DATA_PATH
    )
except ImportError:
    print("ğŸš¨ config_db.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì„¤ì • ì„í¬íŠ¸ ì˜¤ë¥˜.")
    sys.exit(1)


# --- 1. Qdrant ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def recreate_qdrant_collection(client: QdrantClient, collection_name: str, vector_dim: int):
    """ì§€ì •ëœ ì´ë¦„ìœ¼ë¡œ Qdrant ì»¬ë ‰ì…˜ì„ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        print(f"\nQdrant ì»¬ë ‰ì…˜ '{collection_name}'ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš© (Solar ëª¨ë¸ í‘œì¤€)
        client.recreate_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(size=vector_dim, distance=Distance.COSINE)
        )
        print(f"ì»¬ë ‰ì…˜ '{collection_name}' (ì°¨ì›: {vector_dim}) ì¤€ë¹„ ì™„ë£Œ.")
        return True
    except Exception as e:
        print(f"ğŸš¨ Error: Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ. Qdrant ì„œë²„ ìƒíƒœ í™•ì¸ í•„ìš”: {e}")
        return False


def upload_batch(client: QdrantClient, collection_name: str, points: List[PointStruct]):
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ Qdrantì— í¬ì¸íŠ¸ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤."""
    client.upsert(
        collection_name=collection_name,
        points=points,
        wait=True
    )


# --- 2. Text RAG ë°ì´í„° ë¡œë“œ ë° ì¸ë±ì‹± ë¡œì§ ---

def load_and_tag_documents(path: Path, glob_pattern: str, source_type: str) -> List[Document]:
    """ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ë©”íƒ€ë°ì´í„°ë¥¼ íƒœê·¸í•©ë‹ˆë‹¤."""
    target_path = TEXT_DATA_PATH / path
    if not target_path.exists():
        print(f"ê²½ê³ : ë°ì´í„° ê²½ë¡œ '{target_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return []

    print(f"Loading {source_type} documents from {target_path} (Glob: {glob_pattern})...")

    # PDF, HTML, MD ë“± ë‹¤ì–‘í•œ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ DirectoryLoader ì‚¬ìš©
    loader = DirectoryLoader(
        str(target_path),
        glob=glob_pattern,
        show_progress=True,
        use_multithreading=True,
        silent_errors=True
    )

    documents = loader.load()

    for doc in documents:
        doc.metadata["source_type"] = source_type
        doc.metadata["language"] = "generic_text"
        doc.metadata["source"] = doc.metadata.get("source", str(target_path.name))  # ì†ŒìŠ¤ íŒŒì¼/í´ë” ì´ë¦„

    print(f"Loaded {len(documents)} {source_type} documents.")
    return documents


def index_documents_to_qdrant(documents: List[Document], collection_name: str, client: QdrantClient,
                              embed_model: UpstageEmbeddings):
    """ë¬¸ì„œë¥¼ ë¶„í• í•˜ê³  ì„ë² ë”©í•˜ì—¬ ì§€ì •ëœ Qdrant ì»¬ë ‰ì…˜ì— ì €ì¥í•©ë‹ˆë‹¤."""

    if not documents:
        print(f"ê²½ê³ : {collection_name}ì— ì €ì¥í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print(f"\n--- Text RAG Processing for Collection: {collection_name} ---")

    # ë¬¸ì„œ ë¶„í•  (ì²­í¬)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
    )
    texts = text_splitter.split_documents(documents)
    print(f"Split documents into {len(texts)} chunks.")

    # ì„ë² ë”© ìƒì„± (Solar API í˜¸ì¶œ)
    print(f"Generating embeddings for {len(texts)} chunks using {TEXT_EMBEDDING_MODEL}...")
    text_list = [t.page_content for t in texts]
    vectors = embed_model.embed_documents(text_list)

    points_to_upload: List[PointStruct] = []

    for i, vector in enumerate(tqdm(vectors, desc=f"Uploading {collection_name}")):
        doc = texts[i]

        payload = doc.metadata
        payload['page_content'] = doc.page_content  # ì›ë³¸ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ payloadì— ì €ì¥

        points_to_upload.append(
            PointStruct(
                id=str(uuid.uuid4()),  # ê³ ìœ  ID ìƒì„±
                vector=vector,
                payload=payload
            )
        )

    upload_batch(client, collection_name, points_to_upload)

    count = client.count(collection_name=collection_name, exact=True).count
    print(f"âœ… {collection_name} ì—…ë¡œë“œ ì™„ë£Œ. ì´ í¬ì¸íŠ¸: {count}")


# --- 3. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---

def main():
    print("--- Text RAG Vector DB êµ¬ì¶• ì‹œì‘ ---")

    try:
        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
    except Exception as e:
        print(f"ğŸš¨ Qdrant ì„œë²„ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. {QDRANT_URL}")
        print("Qdrant Docker ë˜ëŠ” ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)

    # 1. ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
    recreate_qdrant_collection(client, TEXT_COLLECTION_NAME, TEXT_VECTOR_DIMENSION)
    recreate_qdrant_collection(client, RULE_COLLECTION_NAME, TEXT_VECTOR_DIMENSION)

    # 2. Text RAG ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    os.environ["UPSTAGE_API_KEY"] = UPSTAGE_API_KEY
    if not UPSTAGE_API_KEY:
        print("ğŸš¨ UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ Text RAG ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sys.exit(1)

    embed_model = UpstageEmbeddings(model=TEXT_EMBEDDING_MODEL)
    print(f"âœ… Text Embedding Model ({TEXT_EMBEDDING_MODEL}) ë¡œë“œ ì™„ë£Œ.")

    # 3. Text DB ì—…ë¡œë“œ (KISA + OWASP)
    kisa_docs = load_and_tag_documents(Path("raw/text_kisa"), "*.pdf", "KISA_SecureCoding")
    owasp_docs = load_and_tag_documents(Path("raw/text_owasp"), "*.html", "OWASP_CheatSheet")
    text_db_documents = kisa_docs + owasp_docs
    index_documents_to_qdrant(text_db_documents, TEXT_COLLECTION_NAME, client, embed_model)

    # 4. Rule DB ì—…ë¡œë“œ (Semgrep Docs)
    semgrep_docs = load_and_tag_documents(Path("raw/text_semgrep"), "*.md", "Semgrep_Autofix")
    index_documents_to_qdrant(semgrep_docs, RULE_COLLECTION_NAME, client, embed_model)

    print("\n--- âœ… Text RAG Vector DB êµ¬ì¶• ì™„ë£Œ! (text_db, rule_db) ---")


if __name__ == "__main__":
    main()
